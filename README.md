# test9
scoring classifier
Согласно заданию были проделаны следующие этапы работы. Код с подробнейшими комментариями и анализом находится в Jupyter Notebook model.ipynb.

1. На этапе предварительного анализа данных был рассмотрен датасет, типы данных, количество записей, выведены основные статистические характеристики признаков. Были рассмотрены характеристики признаков в зависимости от принадлежности их к одному из двух целевых классов, сделаны выводы на основе отличий этих признаков. После фильтрации также построены некоторые визуализации.

2. На этапе фильтрации найдены пропуски в данных (поле first_loan), предложены методы заполнения пропусков в зависимости от принадлежности записи к одному из целевых классов. Удалены дублирующиеся записи (с одинаковым order_id), а также с разным order_id, но одновременно совпадающими датой подачи и идентификатором клиента (client_id и order_date). Вывод о необходимости последнего был сделан на основе анализа данных по клиентам, сделавшим более одной заявки. Были удалены выбросы. В качестве критерия использовалась полоса mean+/-3 std. Однако, так как признаки не имеют распределения, близкого к нормальному, не везде выбросы удалось удалить таким образом (возможно нужна дополнительная нормализация данных).

3. На этапе преобразования добавлены несколько новых признаков, описанных в model.ipynb, датасет разбит на тренировочную и тестовую части, проведена нормализация для дальнейшего использования данных в классификаторах.

4. Построены классификаторы на основе логистической регрессии и решающих деревьях (очень логичных для задач типа выдачи кредитов). Отмечу, что подбором гиперпараметров модели я не занимался.

5. В силу несбалансированности данных (74.4% составляют отказы), если просто предсказывать всем отказы, то мы уже получим довольно высокий результат в 75%. Хорошо бы видеть, кроме всего прочего, насколько хорошо предсказываются одобрения.
Метрики, прежде всего, определяются бизнесом. Надо понимать задачу бизнеса, а уже после наиболее грамотно выбрать метрику. Все основные метрики, используемые для классификатора выведены в model.ipynb.
Отмечу, что обе модели дают accuracy несколько больше 80%, при этом recall для отказов/одобрений составили 92%/46% у логистической регрессии и 89%/63% для решающих деревьев.
